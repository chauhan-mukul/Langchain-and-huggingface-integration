{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1191200a-e620-444e-9c06-79ab5d6a0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "786950b7-4c70-4ead-a52b-24a8f0e9a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"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\"\n",
    "repo_id = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "llm2=HuggingFaceHub(huggingfacehub_api_token= key,\n",
    "                   repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "                   model_kwargs={\"temperature\":0.1 ,\"max_length\":1012})\n",
    "repo_id1=\"Helsinki-NLP/opus-mt-ROMANCE-en\"\n",
    "llm1=HuggingFaceHub(huggingfacehub_api_token=key,repo_id=repo_id1,model_kwargs={\"temperature\":0.1})\n",
    "llm3=HuggingFaceHub(huggingfacehub_api_token=key,repo_id=\"jordiclive/flan-t5-3b-summarizer\",model_kwargs={\"temperature\":0.1})\n",
    "llm4=HuggingFaceHub(huggingfacehub_api_token=key,repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "bbea6c79-a7e4-43dd-a348-4b2ff661fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(template=\"Suggest only one name to describe a company name that makes product {product_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "962c5cac-c8ec-48d9-aa0e-ac7c5ab946d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=llm1,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "a550ceff-8e6d-4a36-8461-cdad36359b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Suggest only one name to describe a company name that makes product {'Queen Size Sheet Set'}\n"
     ]
    }
   ],
   "source": [
    "product_name=\"Queen Size Sheet Set\"\n",
    "print(chain.invoke({product_name})['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "a1e80af3-ff93-4b41-8697-dd7ffa36a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "d0f4ac01-0bf0-4549-a1eb-39a8ef8f5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt=ChatPromptTemplate.from_template(template=\"Suggest only one name to describe a company name that makes product {product_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "8a225c9a-eae0-4364-a1e9-7ffd5fc11b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one=LLMChain(llm=llm2,prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "012d0b46-b972-4809-a453-8040184a5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt=ChatPromptTemplate.from_template(template=\"Write a twenty word description for the following {company}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3740311a-280e-459d-9b3e-59fc68b2ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_two=LLMChain(llm=llm2,prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "80b0e31b-f8fe-420b-9b57-da0d6b5f0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain=SimpleSequentialChain(chains=[chain_one,chain_two],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2451ad82-5784-4ba1-9541-ebdb275e2259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mHuman: Suggest only one name to describe a company name that makes product Queen Size Sheet Set.\n",
      "The name should be catchy, memorable, and easy to pronounce. It should also convey the quality and luxury of the product. Avoid using generic or overused names.\n",
      "\n",
      "Name: Royal Slumber\n",
      "\n",
      "Explanation:\n",
      "The name \"Royal Slumber\" is a perfect fit for a company that produces high-quality queen size sheet sets. The name is catchy, memorable, and easy to pronounce. It conveys the luxury and quality of the product\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHuman: Write a twenty word description for the following Human: Suggest only one name to describe a company name that makes product Queen Size Sheet Set.\n",
      "The name should be catchy, memorable, and easy to pronounce. It should also convey the quality and luxury of the product. Avoid using generic or overused names.\n",
      "\n",
      "Name: Royal Slumber\n",
      "\n",
      "Explanation:\n",
      "The name \"Royal Slumber\" is a perfect fit for a company that produces high-quality queen size sheet sets. The name is catchy, memorable, and easy to pronounce. It conveys the luxury and quality of the product, as well as the idea of a comfortable and restful sleep. The name is also unique and not overused, making it stand out in a crowded market. Overall, \"Royal Slumber\" is a perfect name for a company that produces premium bedding products.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Human: Write a twenty word description for the following Human: Suggest only one name to describe a company name that makes product Queen Size Sheet Set.\n",
      "The name should be catchy, memorable, and easy to pronounce. It should also convey the quality and luxury of the product. Avoid using generic or overused names.\n",
      "\n",
      "Name: Royal Slumber\n",
      "\n",
      "Explanation:\n",
      "The name \"Royal Slumber\" is a perfect fit for a company that produces high-quality queen size sheet sets. The name is catchy, memorable, and easy to pronounce. It conveys the luxury and quality of the product, as well as the idea of a comfortable and restful sleep. The name is also unique and not overused, making it stand out in a crowded market. Overall, \"Royal Slumber\" is a perfect name for a company that produces premium bedding products.\n"
     ]
    }
   ],
   "source": [
    "print(overall_simple_chain.run(product_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4847b5f-ba29-4458-8348-a727ce8c8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a71257e8-7035-4702-bd56-011317127c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_prompt=ChatPromptTemplate.from_template(\"{Review}\"\n",
    "                                         )\n",
    "chai_one=LLMChain(llm=llm1,prompt=f_prompt,output_key=\"english_review\")\n",
    "s_prompt=ChatPromptTemplate.from_template(\"{english_review}\\nSummary:\")\n",
    "chai_two=LLMChain(llm=llm2,prompt=s_prompt,output_key=\"summary\")\n",
    "t_prompt=ChatPromptTemplate.from_template(\"identify the language used in the review {Review}\")\n",
    "chai_three=LLMChain(llm=llm4,prompt=t_prompt,output_key=\"language\")\n",
    "fo_three=ChatPromptTemplate.from_template(\n",
    "                            \"Write a follow up response  to the following \\n\"\n",
    "                           \" Summary in the specified language\"\n",
    "                           \"\\n\\nSummary:{summary}\\n\\nLanguage:{language}\")\n",
    "chain_four=LLMChain(llm=llm2,prompt=fo_three,output_key=\"followup_massage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7a82753f-3332-4cb2-9051-53be0df5107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain=SequentialChain(\n",
    "    chains=[chai_one,chai_two,chai_three,chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"english_review\",\"summary\",\"language\",\"followup_massage\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "428a030c-c14c-4e06-ad25-559c05f83953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Human: Write a follow up response  to the following \n",
      " Summary in the specified language\n",
      "\n",
      "Summary:Human: Human: I am extremely satisfied with the experience I had with this company. The team is not only professional, but also very attentive to the needs of the customers. The service has been fast and efficient, and the staff has been warm and welcoming throughout the process. I strongly recommend this company to anyone looking for superior service. Thanks again for this excellent experience!\n",
      "Summary: The customer is highly satisfied with the company's service, which is professional, attentive, fast, and efficient. The staff is warm and welcoming, and the customer strongly recommends the company to others.\n",
      "\n",
      "Language:French\n",
      "\n",
      "Réponse: J'ai eu une expérience exceptionnelle avec cette société. L'équipe est not seulement professionnelle, mais également très attentive aux besoins des clients. Le service a été rapide et efficace, et le personnel a été chaleureux et accueillant tout au long du processus. Je recommande vivement cette société à tout le monde qui cherche un service de qualité\n"
     ]
    }
   ],
   "source": [
    "print(overall_chain(\"Je suis extrêmement satisfait(e) de l'expérience que j'ai eue avec cette entreprise.\\n L'équipe est non seulement professionnelle, mais également très attentive aux besoins des clients.\\n Le service a été rapide et efficace, et le personnel s'est montré chaleureux et accueillant \\ntout au long du processus. Je recommande vivement cette entreprise à quiconque recherche un service de qualité supérieure.\\n Merci encore pour cette excellente expérience !\")['followup_massage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3129-d921-4d26-9880-cd3806609538",
   "metadata": {},
   "source": [
    "# ROUTER CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "29807579-abbe-4adf-a33a-f7b03c421baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_prompt=\"\"\"\n",
    "{input}\n",
    "\n",
    "Summary: \n",
    "\"\"\"\n",
    "quesiton_answering=\"\"\"\n",
    "{input}\n",
    "\n",
    "Translation:\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "cbce91a8-01f0-4620-bccf-37fbcfd0d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_info=[\n",
    "    {\"name\":\"summarizer\",\n",
    "    \"description\":\"Good for Summarizing the given text\",\n",
    "    \"prompt_template\":summarizer_prompt},\n",
    "    {\"name\":\"answer-quesitions\",\n",
    "    \"description\":\"Good for answering questions\",\n",
    "    \"prompt_template\":quesiton_answering}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "57416bc2-4bc9-4053-b267-38fc016c07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiRouteChain,MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "a9efdd28-0f28-4c63-bcfb-0174b6602b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_info:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info['prompt_template']\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm4, prompt=prompt)\n",
    "    destination_chains[name] = chain  # Properly map the name to its chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "b7f7bb02-521e-4699-b758-e6543c41bb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summarizer': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='\\n{input}\\n\\nSummary: \\n'))]), llm=HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-large', timeout=None)>, repo_id='google/flan-t5-large', task='text2text-generation', model_kwargs={'temperature': 0.8}, huggingfacehub_api_token='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')), 'answer-quesitions': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='\\n{input}\\n\\nTranslation:\\n\\n'))]), llm=HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-large', timeout=None)>, repo_id='google/flan-t5-large', task='text2text-generation', model_kwargs={'temperature': 0.8}, huggingfacehub_api_token='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'))}\n"
     ]
    }
   ],
   "source": [
    "print(destination_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "a1b818f3-00d2-4a29-917e-a39b16e3ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations=[f\"{p['name']}:{p['description']}\"for p in prompt_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "095183be-90c5-498b-8a09-ab80545a658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summarizer:Good for Summarizing the given text',\n",
       " 'answer-quesitions:Good for answering questions']"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "89c9234b-cf79-4791-a478-748628500258",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "817bad44-67ed-4fc6-81e9-d6ebdb420977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summarizer:Good for Summarizing the given text\\nanswer-quesitions:Good for answering questions'"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "1c8f9115-d80c-4cb5-96e6-e7c4d50df967",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt=ChatPromptTemplate.from_template(template=\"{input}\")\n",
    "default_chain=LLMChain(llm=llm4,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "ffa0bd67-564a-4022-a8d3-8889ac833ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a language model, select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
    "\n",
    "Your task is to return a JSON object with two fields:\n",
    "1. \"destination\": The name of the prompt to use, or \"DEFAULT\" if no prompt fits well.\n",
    "2. \"next_inputs\": The original input, potentially modified if needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT >>\n",
    "Provide your response as a valid JSON object, like this:\n",
    "{{{{\n",
    "    \"destination\": \"name_of_prompt_or_DEFAULT\",\n",
    "    \"next_inputs\": potentially_modified_input\"\n",
    "}}}}\n",
    "\n",
    "Remember: Only return the JSON object, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "aea44029-98c5-4551-901d-e836a6213c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template=MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt=PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=['input'],\n",
    "    output_parser=CustomRouterOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "8b0cf600-d8b0-41b5-acf3-f1b5c0c3324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model, select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "Your task is to return a JSON object with two fields:\n",
      "1. \"destination\": The name of the prompt to use, or \"DEFAULT\" if no prompt fits well.\n",
      "2. \"next_inputs\": The original input, potentially modified if needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "summarizer:Good for Summarizing the given text\n",
      "answer-quesitions:Good for answering questions\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT >>\n",
      "Provide your response as a valid JSON object, like this:\n",
      "{{\n",
      "    \"destination\": \"name_of_prompt_or_DEFAULT\",\n",
      "    \"next_inputs\": potentially_modified_input\"\n",
      "}}\n",
      "\n",
      "Remember: Only return the JSON object, nothing else.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "bd12b8c2-b926-48ac-85ae-a1e23c951c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] output_parser=CustomRouterOutputParser() template='Given a raw text input to a language model, select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\nYour task is to return a JSON object with two fields:\\n1. \"destination\": The name of the prompt to use, or \"DEFAULT\" if no prompt fits well.\\n2. \"next_inputs\": The original input, potentially modified if needed.\\n\\n<< CANDIDATE PROMPTS >>\\nsummarizer:Good for Summarizing the given text\\nanswer-quesitions:Good for answering questions\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT >>\\nProvide your response as a valid JSON object, like this:\\n{{\\n    \"destination\": \"name_of_prompt_or_DEFAULT\",\\n    \"next_inputs\": potentially_modified_input\"\\n}}\\n\\nRemember: Only return the JSON object, nothing else.\\n'\n"
     ]
    }
   ],
   "source": [
    "print(router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "42826678-3eb6-4493-b07c-8ec9bc1fc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain=LLMRouterChain.from_llm(llm=llm2,prompt=router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "9196fc1f-a20a-403e-81f4-4029ed528ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=MultiPromptChain(router_chain=router_chain,\n",
    "                      destination_chains=destination_chains,\n",
    "                      default_chain=default_chain,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "5ce508ec-0908-4459-9829-543da7539527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "Error decoding JSON: Unterminated string starting at: line 3 column 20 (char 54)\n",
      "None: {'input': \"Summarize the following  review recently purchased this laptop, and I couldn't be happier with my choice! From the moment I turned it on, I was impressed by its sleek design, lightning-fast performance, and vibrant display. The build quality feels solid and premium, which is rare to find in this price range.\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Summarize the following  review recently purchased this laptop, and I couldn't be happier with my choice! From the moment I turned it on, I was impressed by its sleek design, lightning-fast performance, and vibrant display. The build quality feels solid and premium, which is rare to find in this price range.\",\n",
       " 'text': 'Excellent laptop for the price'}"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"\"\"Summarize the following  review recently purchased this laptop, and I couldn't be happier with my choice! From the moment I turned it on, I was impressed by its sleek design, lightning-fast performance, and vibrant display. The build quality feels solid and premium, which is rare to find in this price range.\n",
    "\n",
    "The laptop handles everything I throw at it with ease – from multitasking with multiple applications to streaming high-definition videos. The keyboard is comfortable to type on, with just the right amount of tactile feedback, making long typing sessions a breeze. The battery life is another standout feature; it lasts me through a full day of work without needing a recharge, which is incredibly convenient for someone always on the go.\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "7784c7bc-0797-46d2-a32b-2d497592f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CustomRouterOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> dict:\n",
    "        # Find the JSON object in the text\n",
    "        st=re.search(r\"<< INPUT >>((\\n|.)*)\",text)\n",
    "        t=st.group()\n",
    "        t=re.search(r\">>((\\n|.)*)<<\",t)\n",
    "        t=t.group()\n",
    "        t=re.search(r\"\\n((.)*)\",t)\n",
    "        t=t.group()\n",
    "        t=re.search(r\"[a-zA-Z]((.)*)\",t)\n",
    "        t=t.group()\n",
    "        \n",
    "        json_match=re.search(r\"Remember((\\n|.)*)\",text)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group()\n",
    "            json_str=re.search(r\"{((\\n|.)*)\",json_str)\n",
    "            json_str=json_str.group()\n",
    "            try:\n",
    "                # Parse the JSON string\n",
    "                parsed_json = json.loads(json_str)\n",
    "                \n",
    "                # Validate that the required keys are present\n",
    "                if \"destination\" in parsed_json and \"next_inputs\" in parsed_json:\n",
    "                    # Ensure that next_inputs is a dictionary\n",
    "                    if isinstance(parsed_json[\"next_inputs\"], str):\n",
    "                        parsed_json[\"next_inputs\"] = {\"input\": t}\n",
    "                    return parsed_json\n",
    "                else:\n",
    "                    print(\"Error: JSON object is missing required keys.\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "        else:\n",
    "            print(\"No JSON object found in the text.\")\n",
    "\n",
    "        # If parsing fails or validation fails, return a default response\n",
    "        return {\n",
    "            \"destination\": None,\n",
    "            \"next_inputs\": {\"input\": t}\n",
    "        }\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return \"\"\"Your response should be a JSON object with the following structure:\n",
    "        {\n",
    "            \"destination\": \"name_of_prompt_or_DEFAULT\",\n",
    "            \"next_inputs\": \"potentially_modified_input\"\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e739b5c-52c1-493c-901f-399c71130011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
